{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Top Doc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3: Wrangling OpenStreetMap Data\n",
    "\n",
    "## Udacity Data Analyst NanoDegree\n",
    "___\n",
    "#### Los Angeles, California, USA\n",
    "\n",
    "### Contents\n",
    "___\n",
    "\n",
    "1. [Map Data](#Map-Data)\n",
    "2. [Data Audit](#Data-Audit)\n",
    "  1. [Data Structure](#Data-Structure)\n",
    "  2. [Tag Attributes and Values](#Tag-Attributes-and-Values)\n",
    "    1. [Node Tags Audit](#Node-tags)\n",
    "    2. [Way Tags Audit](#Way-tags)\n",
    "3. [Data Cleaning](#Data-Cleaning)\n",
    "4. [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Data\n",
    "___\n",
    "\n",
    "##### Los Angeles, California, USA\n",
    "[Mapzen](https://mapzen.com/data/metro-extracts/metro/los-angeles_california): `https://mapzen.com/data/metro-extracts/metro/los-angeles_california`\n",
    "\n",
    "I downloaded the initial los-angeles_california.osm dataset from Mapzen (not included in the repository). The original dataset is 8.6 GB large, and after trying to run some of the code from the courses locally, it crashed my computer. I proceeded to make a series of sample files to use (based off of the sample.py script given in the Project Details), which are described in this table:\n",
    "\n",
    "##### Sample files used for Project\n",
    "Name | K-val | Size | Lines | Note\n",
    "---|---:|---:|---:|---|\n",
    "*la-sample.osm* | 1,000 | 8.6 MB | 110,729 | This file was used to test early python data auditing and cleaning scripts.\n",
    "*la-med.osm* | 500 | 17.4 MB | 222,181 | Used as an intermediate test of the data auditing and cleaning scripts. Not included in this repository.\n",
    "*la-final.osm* | 150 | 58.0 MB | 741,172 | Final file used for auditing, cleaning, and importing into the MongoDB database. Not included in this repository, but can be added for resubmission if necessary.\n",
    "\n",
    "[Back To Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Audit\n",
    "___\n",
    "#### Data Structure\n",
    "\n",
    "After reviewing the [OSM XML Content][1] page, I wanted to check that the sample dataset actually had the tags and structure as described. Mainly that the XML was organized as blocks of ***nodes*** with tags for each node, ***ways*** with tags and references to their respectives nodes, and ***relations*** with tags and references too.\n",
    "\n",
    "Using and modifying the `mapparser.py` code from the MongoDB Case Study for OSM Data, I generated a dictionary with element tag names, counts, and attributes. A simple table with the results can be seen here:\n",
    "\n",
    "[1]: #References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name | Count | Attributes\n",
    "---|---:|---\n",
    "member   | 78     | ref, role, type\n",
    "nd       | 41,121 | ref\n",
    "node     | 37,437 | changeset, id, lat, lon, timestamp, uid, user, version\n",
    "relation | 32     | changeset, id, timestamp, uid, user, version\n",
    "tag      | 24,813 | k, v\n",
    "way      | 3,655  | changeset, id, timestamp, uid, user, version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I further modified the `mapparser.py` to see the structure of the data. I named it `data_structure.py` and the results are here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member': {'count': 78},\n",
      " 'nd': {'count': 41121},\n",
      " 'node': {'count': 37437,\n",
      "          'tag': {'attributes': {'k': 968, 'v': 968}, 'count': 968}},\n",
      " 'osm': {'count': 1,\n",
      "         'node': {'attributes': {'changeset': 37437,\n",
      "                                 'id': 37437,\n",
      "                                 'lat': 37437,\n",
      "                                 'lon': 37437,\n",
      "                                 'timestamp': 37437,\n",
      "                                 'uid': 37437,\n",
      "                                 'user': 37437,\n",
      "                                 'version': 37437},\n",
      "                  'count': 37437},\n",
      "         'relation': {'attributes': {'changeset': 32,\n",
      "                                     'id': 32,\n",
      "                                     'timestamp': 32,\n",
      "                                     'uid': 32,\n",
      "                                     'user': 32,\n",
      "                                     'version': 32},\n",
      "                      'count': 32},\n",
      "         'way': {'attributes': {'changeset': 3655,\n",
      "                                'id': 3655,\n",
      "                                'timestamp': 3655,\n",
      "                                'uid': 3655,\n",
      "                                'user': 3655,\n",
      "                                'version': 3655},\n",
      "                 'count': 3655}},\n",
      " 'relation': {'count': 32,\n",
      "              'member': {'attributes': {'ref': 78, 'role': 78, 'type': 78},\n",
      "                         'count': 78},\n",
      "              'tag': {'attributes': {'k': 205, 'v': 205}, 'count': 205}},\n",
      " 'tag': {'count': 24813},\n",
      " 'way': {'count': 3655,\n",
      "         'nd': {'attributes': {'ref': 41121}, 'count': 41121},\n",
      "         'tag': {'attributes': {'k': 23640, 'v': 23640}, 'count': 23640}}}\n"
     ]
    }
   ],
   "source": [
    "run data_structure.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right away, you can see that ***nodes***, ***ways***, and ***members*** do in fact have the ***tag*** and ***nd*** tags as described by the OSM XML Content page. I also printed out the attributes, and nothing seems out of place. Further, the counts for each of the attributes matches the count of the tags themselves, so I don't have to worry about fixing any of those.\n",
    "\n",
    "Interestingly, there are some uncertainties mentioned some problems that could merit further investigation if the data cleaning and auditing functions were to be used as a service in any way. Of note are that id or usernames not necessarily being present, untagged unconnected nodes, element IDs that are negative, among others. It would be important to implement a solution to check and correct these problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag Attributes and Values\n",
    "\n",
    "The attributes for the tags member, nd, node, relation, and way seem to be fairly straightforward and easy to organize, so my Data Cleaning plan will organize those in a simple manner. However, the tag attributes may be a little more difficult to work with. Since the attribute ***k*** represents ***key***, which is assigned by the human user, there can be any number of different values for the k attribute.\n",
    "\n",
    "Again, I modified an example of the course code to make audit.py, which looks at the k values for tags of the given tag type. I ran it for both ***node*** and ***way*** tags, and found some interesting results. The lists were very long, so I will go over the issues that stand out below. To evaluate specific tag values, I'm using the function `tag_search(filename, tag_name, regex)` in the audit.py file, with an example below. The `regex` value was changed for each tag attribute investigated.\n",
    "\n",
    "___\n",
    "##### Node tags\n",
    "**addr:street** and **addr:street_direction_prefix** - these could be redundant, but I will have to review a few samples to see if this is worth correcting. Running the following code\n",
    "```python\n",
    "from audit import tag_search\n",
    "import pprint\n",
    "\n",
    "results = tag_search(\"data/la-small.osm\", \"node\", r'addr:street')\n",
    "pprint.pprint(results)\n",
    "```\n",
    "results in a single tag having the **addr:street_direction_prefix** key. Specifically, `{'k':'addr:street_direction_prefix', 'v': 'W'}`, meaning that I may be able to include this value with it's accompanying **addr:street** tag, if they are tags of the same node. Further, we can use the same code and change the regular expression\n",
    "\n",
    "**Color** and **Colour** - Simply, the **color** and **colour** keys are going to be the same thing. Since this is LA, I'm going to change all **colour** keys to **color** when cleaning.\n",
    "\n",
    "**Fixme** - There was one of these tags, and I may just exclude it in cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'k': 'fixme', 'v': 'Transfer_info'}]\n"
     ]
    }
   ],
   "source": [
    "from audit import tag_search\n",
    "import pprint\n",
    "\n",
    "results = tag_search(\"data/la-small.osm\", \"node\", r'fixme')\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is_in** - This field returns redundant information, such as the state, country that the nodes are located in. Since I am evaluating Los Angeles, California, all these nodes should be in California, and most definitely in the US. I am going to exclude these tags from the database.\n",
    "\n",
    "**GNIS** - Finally, it appears that someone has somehow (programmatically or not) included data from the United States Geographic Service - Geographic Names Information Service ([USGS GNIS][1]) as tags for certain nodes. After doing a little research, it appears that in 2009 US GNIS data was bulk imported into OSM. According to the OSM wiki entry, the GNIS is a database of \"names\" and not \"features\" and further, that many of these entries are incorrect or no longer exist. This poses a fantastic challenge to OSM, and would be a great opportunity for programmatically cleaning the OSM database, which I will discuss in review below. Using tag_search, it doesn't look like there is much of value in these tags, at least for this project. I am going to exclude these tags as well.\n",
    "\n",
    "Other than these, every other tag is fairly straightforward.\n",
    "___\n",
    "##### Way tags\n",
    "\n",
    "**FIXME**, **FMMP**, **NHD**, **NHS**, **gnis** - These will be ignored\n",
    " \n",
    "**tiger:** - oddly, I found a series of tags with keys that had **tiger:** in them.\n",
    "[1]: #References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'k': 'tiger:cfcc', 'v': 'A74'},\n",
      " {'k': 'tiger:tlid', 'v': '195710849:195710852'},\n",
      " {'k': 'tiger:county', 'v': 'San Diego, CA'},\n",
      " {'k': 'tiger:source', 'v': 'tiger_import_dch_v0.6_20070809'},\n",
      " {'k': 'tiger:reviewed', 'v': 'no'},\n",
      " {'k': 'tiger:upload_uuid',\n",
      "  'v': 'bulk_upload.pl-5dac241b-d144-4c9c-9e26-b4dec4590a61'}]\n"
     ]
    }
   ],
   "source": [
    "results = tag_search(\"data/la-small.osm\", \"way\", r'tiger:')\n",
    "pprint.pprint(results[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these look like some sort of algorithmic utility for uploading data to OSM. Further investigation proves this to be correct, as TIGER stands for \"The Topologically Integrated Geographic Encoding and Referencing system (TIGER) data,[which is] produced by the US Census Bureau, is a public domain data source which has many geographic features. The TIGER/Line files are extracts of selected geographic information, including roads, boundaries, and hydrography features. All of the roads were imported into OSM in 2007 and 2008, populating the nearly empty map of the United States.\" from the [OSM wiki page][1]. I am going to exclude these as well, as the wiki explains that much of the US mapping is now done by the OSM mapping community, as mass uploads of the TIGER data stopped after 2007, and should be unimportant to the analysis for this project.\n",
    "\n",
    "Other than these, the other tags should clean well, and any issues in the tags' key values will have to be the subject of a secondary cleaning.\n",
    "\n",
    "[1]: #References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "___\n",
    "\n",
    "I modified the data.py code from the final quiz in the MongoDB for OSM Case study as a base script for shaping and converting the osm data into json.\n",
    "\n",
    "\n",
    "[Back To Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "___\n",
    "\n",
    "1. [OSM: XML Contents wiki](https://wiki.openstreetmap.org/wiki/OSM_XML#Contents): `https://wiki.openstreetmap.org/wiki/OSM_XML#Contents`\n",
    "2. [OSM: USGS GSM wiki](http://wiki.openstreetmap.org/wiki/USGS_GNIS): `http://wiki.openstreetmap.org/wiki/USGS_GNIS`\n",
    "3. [OSM: TIGER wiki](http://wiki.openstreetmap.org/wiki/TIGER): `http://wiki.openstreetmap.org/wiki/TIGER`\n",
    "___\n",
    "[Back To Contents](#Contents)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dandy]",
   "language": "python",
   "name": "conda-env-dandy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
